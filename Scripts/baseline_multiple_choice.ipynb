{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_df = pd.read_csv('data/aspect_category_final.csv')\n",
    "with open('final_data.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    # next(reader, None)  # skip the headers\n",
    "    final_data = [row for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = []\n",
    "for dat in final_data:\n",
    "    tags.append(dat[2])\n",
    "    \n",
    "tags = list(set(tags))\n",
    "\",\".join(tags)\n",
    "tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
    "idx2tag = {idx:tag for idx, tag in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "celtic-colony",
=======
   "id": "joint-median",
>>>>>>> cf1e82b53edad556b7eedee07479ce474061612f
   "metadata": {},
   "outputs": [],
   "source": [
    "ending_names = [\"is a hero\", \"is a villain\", \"is a victim\"]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    first_sentences = [[context] * 3 for context in examples[\"sentence\"]]\n",
    "    question_headers = examples[\"aspect\"]\n",
    "    second_sentences = [\n",
    "     [f\"{header} {end}\" for end in ending_names] for i, header in enumerate(question_headers)\n",
    "    ]\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    print(second_sentences)\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    return {k: [v[i : i + 3] for i in range(0, len(v), 3)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "voluntary-salmon",
=======
   "id": "ultimate-accommodation",
>>>>>>> cf1e82b53edad556b7eedee07479ce474061612f
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"csv\", data_files = {\"train\": \"train_data.csv\", \"test\": \"test_data.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "classified-necessity",
=======
   "id": "lightweight-bunch",
>>>>>>> cf1e82b53edad556b7eedee07479ce474061612f
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = data.map(preprocess_function,batched=True)\n",
    "# columns_to_return = ['input_ids', 'token_type_ids', 'attention_mask']\n",
    "# tokenized_data.set_format(type='torch', columns=columns_to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "found-change",
=======
   "id": "welsh-heaven",
>>>>>>> cf1e82b53edad556b7eedee07479ce474061612f
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        labels = [tag2idx[k] for k in labels]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0][\"input_ids\"])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "excess-australia",
=======
   "id": "consistent-portal",
>>>>>>> cf1e82b53edad556b7eedee07479ce474061612f
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForMultipleChoice.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "assured-merchandise",
=======
   "id": "subsequent-logan",
>>>>>>> cf1e82b53edad556b7eedee07479ce474061612f
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "     output_dir=\"./results\",\n",
    "     evaluation_strategy=\"epoch\",\n",
    "     learning_rate=5e-5,\n",
    "     per_device_train_batch_size=16,\n",
    "     per_device_eval_batch_size=16,\n",
    "     num_train_epochs=3,\n",
    "     weight_decay=0.01,\n",
    " )\n",
    "\n",
    "trainer = Trainer(\n",
    "     model=model,\n",
    "     args=training_args,\n",
    "     train_dataset=tokenized_data[\"train\"],\n",
    "     eval_dataset=tokenized_data[\"test\"],\n",
    "     tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer)\n",
    " )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "familiar-notion",
=======
   "id": "formal-dispatch",
>>>>>>> cf1e82b53edad556b7eedee07479ce474061612f
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
