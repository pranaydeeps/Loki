{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disciplinary-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import ast\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampling = 0.5\n",
    "oversampling = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virgin-strengthening",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('testFinal.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "memes_df = pd.read_csv('textAllEntities.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "memes_df2 = pd.read_csv('textAllEntities_politics.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "memes_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "memes_df = pd.concat([memes_df, memes_df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "memes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "memes_df = memes_df[[\"OCR\",\"hero\",\"villain\",\"victim\",\"other\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlimited-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[[\"OCR\",\"entity_list\",\"image\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "reformatted_memes = []\n",
    "skipped = 0\n",
    "for i, text in enumerate(memes_df[\"OCR\"]):\n",
    "    text = str(text).replace(\"\\n\",\" \")\n",
    "\n",
    "    try:\n",
    "        hero = ast.literal_eval(memes_df[\"hero\"][i])\n",
    "    except:\n",
    "        hero = []\n",
    "    try:\n",
    "        villain = ast.literal_eval(memes_df[\"villain\"][i])\n",
    "    except:\n",
    "        villain = []\n",
    "    try:\n",
    "        victim = ast.literal_eval(memes_df[\"victim\"][i])\n",
    "    except:\n",
    "        victim = []\n",
    "    try:\n",
    "        other = ast.literal_eval(memes_df[\"other\"][i])\n",
    "    except:\n",
    "        other = []\n",
    "    if text == 'nan':\n",
    "        skipped+=1\n",
    "        continue\n",
    "    if len(text)==0:\n",
    "        skipped+=1\n",
    "        continue\n",
    "    for j in hero:\n",
    "        if len(j)==0:\n",
    "            skipped+=1\n",
    "            continue\n",
    "        reformatted_memes.append([text, j, \"hero\"])\n",
    "    for j in villain:\n",
    "        if len(j)==0:\n",
    "            skipped+=1\n",
    "            continue\n",
    "        reformatted_memes.append([text, j, \"villain\"])\n",
    "    for j in victim:\n",
    "        if len(j)==0:\n",
    "            skipped+=1\n",
    "            continue\n",
    "        reformatted_memes.append([text, j, \"victim\"])\n",
    "    for j in other:\n",
    "        if len(j)==0:\n",
    "            skipped+=1\n",
    "            continue\n",
    "        reformatted_memes.append([text, j, \"other\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "entertaining-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_memes = []\n",
    "skipped = 0\n",
    "for i, text in enumerate(test_df[\"OCR\"]):\n",
    "    text = str(text).replace(\"\\n\",\" \")\n",
    "    entities = ast.literal_eval(test_df[\"entity_list\"][i])\n",
    "    for j in entities:\n",
    "        test_memes.append([text, j, test_df[\"image\"][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comprehensive-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2433"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_memes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "south-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_testdata.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(test_memes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reformatted_memes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(reformatted_memes, shuffle=True, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_train = []\n",
    "for item in train:\n",
    "    if \"other\" in item[2]:\n",
    "        if random.random()>undersampling:\n",
    "            continue\n",
    "        else:\n",
    "            resample_train.append(item)\n",
    "    else:\n",
    "        duplication = random.choice(oversampling)\n",
    "        for i in range (0,duplication):\n",
    "            resample_train.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_train = []\n",
    "for item in train:\n",
    "    if \"other\" in item[2]:\n",
    "        if random.random()>undersampling:\n",
    "            continue\n",
    "        else:\n",
    "            resample_train.append(item)\n",
    "    else:    \n",
    "        resample_train.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(resample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_data.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow([\"sentence\",\"aspect\",\"label\"])\n",
    "    writer.writerows(train)\n",
    "with open(\"test_data.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_MINIMAL)\n",
    "    writer.writerow([\"sentence\",\"aspect\",\"label\"])\n",
    "    writer.writerows(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "train_labels = Counter([j[2] for j in train])\n",
    "test_labels = Counter([j[2] for j in test])\n",
    "print(train_labels)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-timber",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
